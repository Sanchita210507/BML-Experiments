{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAIlN6wU0XaTrjdI+NQT3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanchita210507/BML-Experiments/blob/main/Exp_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtjTUHmrJlp6",
        "outputId": "c31ad784-d28d-4051-bbda-4c6bbdee737c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
            "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
            "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
            "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
            "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
            "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
            "\n",
            "   slope   ca  thal  num  \n",
            "0    3.0  0.0   6.0    0  \n",
            "1    2.0  3.0   3.0    1  \n",
            "2    2.0  2.0   7.0    1  \n",
            "3    3.0  0.0   3.0    0  \n",
            "4    1.0  0.0   3.0    0  \n",
            "(297, 14)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = '/content/drive/MyDrive/heart_disease/processed.cleveland.data'\n",
        "\n",
        "# Load dataset without header\n",
        "df = pd.read_csv(path, header=None)\n",
        "\n",
        "# Assign official UCI column names\n",
        "df.columns = [\n",
        "    \"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\n",
        "    \"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\n",
        "    \"slope\",\"ca\",\"thal\",\"num\"\n",
        "]\n",
        "\n",
        "df = df.replace(\"?\", np.nan)\n",
        "df = df.apply(pd.to_numeric)\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert target to binary (0 vs >=1)\n",
        "df[\"num\"] = (df[\"num\"] > 0).astype(int)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(\"num\", axis=1).values\n",
        "y = df[\"num\"].values.reshape(-1, 1)\n",
        "\n",
        "# Scale features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "\n",
        "df.columns\n",
        "\n",
        "# train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Manual Implementation*"
      ],
      "metadata": {
        "id": "dKTEeQ3baGf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Training Logistic Regression from scratch\n",
        "def train_logistic_regression(X, y, lr=0.01, epochs=2000):\n",
        "    m, n = X.shape\n",
        "    W = np.zeros((n, 1))\n",
        "    b = 0\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # Forward propagation\n",
        "        z = np.dot(X, W) + b\n",
        "        y_pred = sigmoid(z)\n",
        "\n",
        "        # Cost (binary cross entropy)\n",
        "        cost = -(1/m) * np.sum(y * np.log(y_pred + 1e-9) + (1-y)*np.log(1-y_pred + 1e-9))\n",
        "\n",
        "        # Gradients\n",
        "        dW = (1/m) * np.dot(X.T, (y_pred - y))\n",
        "        db = (1/m) * np.sum(y_pred - y)\n",
        "\n",
        "        # Update weights\n",
        "        W -= lr * dW\n",
        "        b -= lr * db\n",
        "\n",
        "        # Print loss occasionally\n",
        "        if i % 200 == 0:\n",
        "            print(f\"Epoch {i}, Loss = {cost:.4f}\")\n",
        "\n",
        "    return W, b\n",
        "\n",
        "# Train the model\n",
        "W, b = train_logistic_regression(X_train, y_train)\n",
        "\n",
        "# Prediction\n",
        "def predict(X, W, b):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    return (y_pred >= 0.5).astype(int)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_test = predict(X_test, W, b)\n",
        "accuracy = np.mean(y_pred_test == y_test)\n",
        "print(\"Manual Logistic Regression Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C63BB_faJXv",
        "outputId": "84124eb3-673f-4c3f-cc3b-f8f8d122d58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss = 0.6931\n",
            "Epoch 200, Loss = 0.4442\n",
            "Epoch 400, Loss = 0.4012\n",
            "Epoch 600, Loss = 0.3850\n",
            "Epoch 800, Loss = 0.3768\n",
            "Epoch 1000, Loss = 0.3718\n",
            "Epoch 1200, Loss = 0.3685\n",
            "Epoch 1400, Loss = 0.3662\n",
            "Epoch 1600, Loss = 0.3645\n",
            "Epoch 1800, Loss = 0.3632\n",
            "Manual Logistic Regression Accuracy: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Built-in Method*"
      ],
      "metadata": {
        "id": "_9kaC0qUacCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "model.fit(X_train, y_train.ravel())\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Sklearn Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvBFq6-vagqU",
        "outputId": "5278b740-7884-4c4f-885b-5cea192891ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Logistic Regression Accuracy: 0.8666666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89        36\n",
            "           1       0.83      0.83      0.83        24\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.86      0.86      0.86        60\n",
            "weighted avg       0.87      0.87      0.87        60\n",
            "\n"
          ]
        }
      ]
    }
  ]
}